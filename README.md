# The Zendesk Intellingent Machines Series

## Notebook 1 - Linear models
In this notebook, we build an understanding of the operations that underly every neural neural network: The linear transformation. 

## Notebook 2 - A simple neural network
In this notebook, we use our knowledge of linear combinations to implement a simple neural network from scratch using numpy. We introduce the concept of layers and show how layers of linear transformations can be used to approximate linear functions. We also introduce how to load a dataset, batch it, use it to train the network, and other necessities.

## Notebook 3 - Function Optimization  
In this notebook, we take a dive in to function optimization. We consider two ways to think about optizing a function. First is finding the optimal inputs so as to maximize or minimize the output. Second is to find parameters that minimize the different between the output of the function and some target value. To do this, we introduce the gradient and talk about what it is and how to use it.

## Notebook 4 - Activation Functions and Loss Functions
In this noetbook, we talk about what it means to approximate a function and how to accomplish this using activation functions and loss functions. The function we intend to approximate depends on the task, and the approximation needs to be posed in the form of an appropriate loss function. To understand this, we analyze the properties of a few activation and loss functions and discuss how they work together to drive training in the right direction.
